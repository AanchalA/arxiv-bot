{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArXiv Scraper Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U arxivscraper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all preprints in `\"Computation and Language\"` from the past year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxivscraper\n",
    "\n",
    "scraper = arxivscraper.Scraper(\n",
    "    category='cs',\n",
    "    date_from='2022-01-01',\n",
    "    date_until='2023-02-05',\n",
    "    filters={'categories': ['cs.CL']}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin scraping..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = scraper.scrape()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert records to Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cols = ['id', 'title', 'categories', 'abstract', 'doi', 'created', 'updated', 'authors']\n",
    "df = pd.DataFrame(output, columns=cols)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing PDFs\n",
    "\n",
    "Now we need to process the PDFs to plaintext — this is almost almost always unreasonably difficult to do..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "doi = \"2210.03629\"\n",
    "url = f\"https://arxiv.org/pdf/{doi}.pdf\"\n",
    "\n",
    "# download and save PDF to file\n",
    "r = requests.get(url)\n",
    "with open(f\"{doi}.pdf\", 'wb') as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I haven't tested other simpler PDF readers for a long time, for now will just go with easy option of PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions>=3.10.0.0 in /Users/jamesbriggs/opt/anaconda3/envs/ml/lib/python3.9/site-packages (from PyPDF2) (4.4.0)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "data = {}\n",
    "\n",
    "# open the PDF file in binary read mode\n",
    "with open(f\"{doi}.pdf\", \"rb\") as file:\n",
    "    # create a PDF object\n",
    "    pdf = PyPDF2.PdfReader(file)\n",
    "    data[doi] = \"\"\n",
    "    # iterate over every page in the PDF\n",
    "    for page in range(len(pdf.pages)):\n",
    "        # get the page object\n",
    "        page_obj = pdf.pages[page]\n",
    "        # extract text from the page\n",
    "        text = page_obj.extract_text()\n",
    "        # add text to data\n",
    "        data[doi] += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434\n",
      "REAC T: S YNERGIZING REASONING AND ACTING IN\n",
      "LANGUAGE MODELS\n",
      "Shunyu Yao\u0003*,1, Jeffrey Zhao2, Dian Yu2, Nan Du2, Izhak Shafran2, Karthik Narasimhan1, Yuan Cao2\n",
      "1Department of Computer Science, Princeton University\n",
      "2Google Research, Brain team\n",
      "1{shunyuy,karthikn}@princeton.edu\n",
      "2{jeffreyzhao,dianyu,dunan,izhak,yuancao}@google.com\n",
      "ABSTRACT\n",
      "While large language models (LLMs) have demonstrated impressive performance\n",
      "across tasks in language understanding and interactive decision making, their\n",
      "abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action\n",
      "plan generation) have primarily been studied as separate topics. In this paper, we\n",
      "explore the use of LLMs to generate both reasoning traces and task-speciﬁc actions\n",
      "in an interleaved manner, allowing for greater synergy between the two: reasoning\n",
      "traces help the model induce, track, and update action plans as well as handle\n",
      "exceptions, while actions allow it to interface with and gather additional information\n",
      "from external sources such as knowledge bases or environments. We apply our\n",
      "approach, named ReAct , to a diverse set of language and decision making tasks\n",
      "and demonstrate its effectiveness over state-of-the-art baselines in addition to\n",
      "improved human interpretability and trustworthiness. Concretely, on question\n",
      "answering (HotpotQA) and fact veriﬁcation (Fever), ReAct overcomes prevalent\n",
      "issues of hallucination and error propagation in chain-of-thought reasoning by\n",
      "interacting with a simple Wikipedia API, and generating human-like task-solving\n",
      "trajectories that are more interpretable than baselines without reasoning traces\n"
     ]
    }
   ],
   "source": [
    "data[doi] = data[doi].split('.\\n')\n",
    "print(len(data[doi]))\n",
    "print(data[doi][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can deal with the annoying formatting later, right now I don't think it's important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8e7999f96e1b425e2d542f21b571f5a4be3e97158b0b46ea1b2500df63956ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
