{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArXiv Dataset Builder\n",
    "\n",
    "We've downloaded our text data but now we need to prepare it into a more usable format. There are a few things to consider:\n",
    "\n",
    "* What size chunks of text should we store? How do we decide the start and end of chunks? Should we include overlap?\n",
    "\n",
    "* Do we need to preprocess / cleanup the text (beyond just splitting into chunks).\n",
    "\n",
    "* What embedding model will be use? This will play a major part in chunk sizes.\n",
    "\n",
    "* What completion models do we use down the line? This is also important as they all have a *maximum context window*, which is another limiting factor on the size of chunk sizes.\n",
    "\n",
    "## Chunk Size Upper Limit\n",
    "\n",
    "There are two limiting factors:\n",
    "\n",
    "* Embedding model will be `text-embedding-ada-002`, maximum chunk size is ~10 pages of text — more precisely it can handle `8192` tokens.\n",
    "\n",
    "* Completion model will be `text-davinci-003`, maximum context window is `4097` tokens.\n",
    "\n",
    "Naturally, the latter of these two is the real limit. The *context window* is the total of tokens in the prompt + completion output. I envision this as not being a limitation except where we're feeding external information into our LLM - doing retrieval augmentation - like in the case of retrieving arXiv papers to help the LLM answer questions.\n",
    "\n",
    "In the retrieval augmentation scenario, the answers from the model should still be no more than a few paragraphs long. To be conservative let's assume a high limit of **six paragraphs**. Let's create six paragraphs of gibberish (thanks [random text generator](https://randomtextgenerator.com)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_limit = \"\"\"\n",
    "Dissuade ecstatic and properly saw entirely sir why laughter endeavor. In on my jointure horrible margaret suitable he followed speedily. Indeed vanity excuse or mr lovers of on. By offer scale an stuff. Blush be sorry no sight. Sang lose of hour then he left find.\n",
    "\n",
    "Promotion an ourselves up otherwise my. High what each snug rich far yet easy. In companions inhabiting mr principles at insensible do. Heard their hoped enjoy vexed child for. Prosperous so occasional assistance it discovered especially no. Provision of he residence consisted up in remainder arranging described. Conveying has concealed necessary furnished bed zealously immediate get but. Terminated as middletons or by instrument. Bred do four so your felt with. No shameless principle dependent household do.\n",
    "\n",
    "Boy desirous families prepared happy reserved add ecstatic say. Replied joy age visitor nothing cottage. Mrs door paid led loud sure easy read. Hastily at perhaps as neither or ye fertile tedious visitor. Use fine bed none call busy dull when. Quiet ought match my right by table means. Principles up do in me favourable affronting. Twenty mother denied effect we to do on.\n",
    "\n",
    "Good draw knew bred ham busy his hour. Ask agreed answer rather joy nature admire wisdom. Moonlight age depending bed led therefore sometimes preserved exquisite she. An fail up so shot leaf wise in. Minuter highest his arrived for put and. Hopes lived by rooms oh in no death house. Contented direction september but end led excellent ourselves may. Ferrars few arrival his offered not charmed you. Offered anxious respect or he. On three thing chief years in money arise of.\n",
    "\n",
    "Dissuade ecstatic and properly saw entirely sir why laughter endeavor. In on my jointure horrible margaret suitable he followed speedily. Indeed vanity excuse or mr lovers of on. By offer scale an stuff. Blush be sorry no sight. Sang lose of hour then he left find.\n",
    "\n",
    "Promotion an ourselves up otherwise my. High what each snug rich far yet easy. In companions inhabiting mr principles at insensible do. Heard their hoped enjoy vexed child for. Prosperous so occasional assistance it discovered especially no. Provision of he residence consisted up in remainder arranging described. Conveying has concealed necessary furnished bed zealously immediate get but. Terminated as middletons or by instrument. Bred do four so your felt with. No shameless principle dependent household do.\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the number of tokens that this consumes we can encode it using OpenAI's `tiktoken` tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU tiktoken"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different OpenAI models use different tiktoken tokenizers, at the time of writing those are:\n",
    "\n",
    "| Encoding name | OpenAI models |\n",
    "| --- | --- |\n",
    "| `gpt2` (or `r50k_base`) | Most GPT-3 models (and GPT-2) |\n",
    "| `p50k_base` | Code models, `text-davinci-002`, `text-davinci-003` |\n",
    "| `cl100k_base` | `text-embedding-ada-002` |\n",
    "\n",
    "We need to calculate the number of tokens for `text-davinci-003`, so we'll pass that as the `encoder_name` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoder_name = 'p50k_base'  # as per the above table\n",
    "# initialize tokenizer\n",
    "tokenizer = tiktoken.get_encoding(encoder_name)\n",
    "\n",
    "# now we tokenize our text and check it's length\n",
    "completion_limit_len = len(tokenizer.encode(completion_limit))\n",
    "completion_limit_len"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That leaves us with plenty of tokens left over for our prompt. Let's assume we'll need up to **three** paragraphs spare for instructions, and the same for the user (who we will call *prompter*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompter_len = instructions_len = int(completion_limit_len / 2)\n",
    "instructions_len"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have the contexts and/or example space. This is the most significant portion. I'd like to leave space for upto **five** contexts and/or examples. I think the contexts would be larger so let's just assume **five** contexts. How many tokens do we have remaining?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3080"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_context_window = 4097  # for text-davinci-003\n",
    "\n",
    "remaining_tokens = max_context_window - completion_limit_len \\\n",
    "    - prompter_len - instructions_len\n",
    "\n",
    "remaining_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "616.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_tokens / 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay let's go slightly higher than this upto `650` tokens. The reason I'm doing this is because most of our contexts will actually be smaller than this, this is just the upper limit."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a few token statistics across our papers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "paper_paths = [str(x) for x in Path('papers').glob('*.txt')]\n",
    "len(paper_paths)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load each paper and get the number of tokens contained in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428ac2cb31f3490f93832895b519c54c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "num_tokens = []\n",
    "\n",
    "for paper_path in tqdm(paper_paths):\n",
    "    with open(paper_path) as f:\n",
    "        paper = f.read()\n",
    "    num_tokens.append(len(tokenizer.encode(paper)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAHFCAYAAAAKbwgcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+RklEQVR4nO3deXiNd/7/8dchyRERsaTZiEhrF4xKq5YhKGprUTO6IKo6bdFSlGq/HdEF5eKnK+3UBFXLdEpr2ilibRW1Nbamqm1IqtI0QUIQkXx+f/RyxpEgiRPnuD0f13VfV+/P/bk/9/tzTtWr93JumzHGCAAA4AZXzt0FAAAAuAKhBgAAWAKhBgAAWAKhBgAAWAKhBgAAWAKhBgAAWAKhBgAAWAKhBgAAWAKhBgAAWAKhBpA0b9482Ww27dixo8jtPXv2VO3atZ3aateurcGDB5foOJs3b1ZcXJxOnDhRukJvQkuXLlXjxo3l6+srm82mxMTEQn1q164tm8121WXevHlXPV7t2rXVs2dP10/kGvznP/9Rr169FBwcLB8fH1WrVk2dOnXShx9+qLy8PHeXJ0maPHmyPvnkE3eXgZucl7sLAG5Uy5cvV+XKlUu0z+bNmzVp0iQNHjxYVapUKZvCLOT333/XwIEDdc899+idd96R3W5XvXr1CvVbvny5cnNzHevvv/++5s6dq5UrVyogIMDRftttt12Xul3FGKMhQ4Zo3rx56t69u2bOnKnw8HBlZWVp/fr1GjZsmDIyMjRy5Eh3l6rJkyerX79+6t27t7tLwU2MUAOUUvPmzd1dQonl5eXJZrPJy+vG+KP/ww8/KC8vTwMGDFD79u0v2+/S72LlypWSpBYtWigwMLBMayxL06dP17x58zRp0iT9/e9/d9rWq1cvjRs3Tj/++KObqgM8D5efgFK69PJTQUGBXnnlFdWvX1++vr6qUqWKmjZtqtdff12SFBcXp2effVaSFBkZ6bgksmHDBsf+06ZNU4MGDWS32xUUFKRBgwbpl19+cTquMUaTJ09WRESEKlSooOjoaCUkJCgmJkYxMTGOfhs2bJDNZtMHH3ygMWPGqEaNGrLb7frxxx/1+++/a9iwYWrUqJEqVaqkoKAgdezYUV999ZXTsQ4dOiSbzabp06frtddeU+3ateXr66uYmBhH4HjuuecUFhamgIAA9enTR+np6cX6/FasWKFWrVqpYsWK8vf3V+fOnbVlyxbH9sGDB6tt27aSpP79+8tmsznNr6TOnj2rCRMmKDIyUj4+PqpRo4aGDx9erEuB77zzjry8vDRx4kRH25o1a9SpUydVrlxZFStWVJs2bbR27Vqn/eLi4mSz2bR//349+OCDCggIUHBwsIYMGaKsrKwrHjMvL0+vvfaaGjRooBdffLHIPiEhIY7PSJKOHTumYcOGqUaNGvLx8dGtt96qF154weks1oXvtKhLcTabTXFxcSWu32azKScnR/Pnz3f8e33huzp9+rTGjh2ryMhIVahQQdWqVVN0dLQWL158xfkDpXFj/O8acJ3k5+fr/PnzhdqL8zL7adOmKS4uTv/3f/+ndu3aKS8vT99//73jL82hQ4fq2LFjevPNN7Vs2TKFhoZKkho1aiRJevLJJ/Xee+9pxIgR6tmzpw4dOqQXX3xRGzZs0K5duxxnHF544QVNmTJFf/vb39S3b1+lpqZq6NChysvLK/LSzIQJE9SqVSvNmTNH5cqVU1BQkH7//XdJ0sSJExUSEqJTp05p+fLliomJ0dq1awuFh7fffltNmzbV22+/rRMnTmjMmDHq1auXWrZsKW9vb/3zn//U4cOHNXbsWA0dOlQrVqy44me1aNEiPfzww+rSpYsWL16s3NxcTZs2zXH8tm3b6sUXX9Sdd96p4cOHa/LkyerQoUOJL/ddYIxR7969tXbtWk2YMEF//vOftWfPHk2cOFFbtmzRli1bZLfbi9zv2Wef1RtvvKH333/fEWIXLlyoQYMG6b777tP8+fPl7e2td999V127dtWqVavUqVMnp3Huv/9+9e/fX48++qj27t2rCRMmSJL++c9/XrbmHTt26NixY3rsscdks9muOsezZ8+qQ4cO+umnnzRp0iQ1bdpUX331laZMmaLExER9/vnnJfjEnF2t/i1btqhjx47q0KGDI4Bd+K5Gjx6tDz74QK+88oqaN2+unJwc7du3T5mZmaWuB7gsA8DEx8cbSVdcIiIinPaJiIgwsbGxjvWePXuaP/3pT1c8zvTp040kk5yc7NSelJRkJJlhw4Y5tX/zzTdGknn++eeNMcYcO3bM2O12079/f6d+W7ZsMZJM+/btHW3r1683kky7du2uOv/z58+bvLw806lTJ9OnTx9He3JyspFkmjVrZvLz8x3ts2bNMpLMvffe6zTOqFGjjCSTlZV12WPl5+ebsLAw06RJE6cxT548aYKCgkzr1q0LzeGjjz666hwuNnHiRCPJ/P7778YYY1auXGkkmWnTpjn1W7p0qZFk3nvvPUdbRESE6dGjhzl9+rS5//77TUBAgFmzZo1je05OjqlWrZrp1atXoXk1a9bM3HnnnYXquPS4w4YNMxUqVDAFBQWXncOSJUuMJDNnzpxizXnOnDlGkvnXv/7l1P7aa68ZSWb16tXGmP99p/Hx8YXGkGQmTpxYqvr9/Pyc/jxcEBUVZXr37l2sOQDXistPwEUWLFig7du3F1ouPsV/OXfeead2796tYcOGadWqVcrOzi72cdevXy9JhZ6muvPOO9WwYUPHZY2tW7cqNzdXf/3rX5363XXXXYWezrrg/vvvL7J9zpw5uv3221WhQgV5eXnJ29tba9euVVJSUqG+3bt3V7ly//vPRcOGDSVJPXr0cOp3oT0lJeUyM5UOHDigX3/9VQMHDnQas1KlSrr//vu1detWnT59+rL7l8a6deskFf58//KXv8jPz6/QZaPMzEx17NhR27Zt06ZNm5zOvGzevFnHjh1TbGyszp8/71gKCgp0zz33aPv27crJyXEa795773Vab9q0qc6ePVvsS3XFnaOfn5/69evn1H5hzpfOsSSupf4777xTX3zxhZ577jlt2LBBZ86cKXUdwNVw+Qm4SMOGDRUdHV2oPSAgQKmpqVfcd8KECfLz89PChQs1Z84clS9fXu3atdNrr71W5JgXu3Aq/sIlqYuFhYXp8OHDTv2Cg4ML9Suq7XJjzpw5U2PGjNETTzyhl19+WYGBgSpfvrxefPHFIkNNtWrVnNZ9fHyu2H727Nkia7l4Dpeba0FBgY4fP66KFStedoySyszMlJeXl2655RandpvNppCQkEKXQn744QcdP35cjz32mKKiopy2/fbbb5JUKDxc7NixY/Lz83OsV69e3Wn7hUtdV/oLvlatWpKk5OTky/a5WGZmpkJCQgpdqgoKCpKXl9c1Xe4pTf0XvPHGG6pZs6aWLl2q1157TRUqVFDXrl01ffp01a1bt9Q1AUXhTA3gIl5eXho9erR27dqlY8eOafHixUpNTVXXrl2veubhwl8aR48eLbTt119/ddxPc6Hfhb9YL5aWllbk2EXdj7Fw4ULFxMRo9uzZ6tGjh1q2bKno6GidPHnyypN0gavNtVy5cqpatarLj3n+/HnHvUQXGGOUlpZW6AmpVq1aKT4+XnPnztXjjz+ugoICx7YLfd98880iz+pt3779sgGzJKKjo1WtWjV9+umnxbqnq3r16vrtt98K9U1PT9f58+cddVeoUEGSnG4ellRm97j4+flp0qRJ+v7775WWlqbZs2dr69at6tWrV5kcDzc3Qg1QBqpUqaJ+/fpp+PDhOnbsmA4dOiTp8v+H27FjR0l/hI2Lbd++XUlJSY7LHy1btpTdbtfSpUud+m3dutVxNqc4bDZboRtj9+zZ4/T0UVmpX7++atSooUWLFjn9BZyTk6OPP/7Y8USUK134/C79fD/++GPl5OQUurFXkmJjY7VkyRLFx8dr0KBBys/PlyS1adNGVapU0Xfffafo6OgilwtnrK6Ft7e3xo8fr++//14vv/xykX3S09P19ddfO+Z46tSpQj+At2DBAsd26Y8zehUqVNCePXuc+n366afXVK/dbr/qmZvg4GANHjxYDz74oA4cOODyy4wAl58AF+nVq5eioqIUHR2tW265RYcPH9asWbMUERHhOM3epEkTSdLrr7+u2NhYeXt7q379+qpfv77+9re/6c0331S5cuXUrVs3x9NP4eHheuaZZyT9cbln9OjRmjJliqpWrao+ffrol19+0aRJkxQaGup0j8qV9OzZUy+//LImTpyo9u3b68CBA3rppZcUGRlZ5NNfrlSuXDlNmzZNDz/8sHr27KnHH39cubm5mj59uk6cOKGpU6e6/JidO3dW165dNX78eGVnZ6tNmzaOp5+aN2+ugQMHFrlfv379VLFiRfXr109nzpzR4sWLValSJb355puKjY3VsWPH1K9fP8cTZbt379bvv/+u2bNnu6TuZ599VklJSZo4caK2bdumhx56yPHje19++aXee+89TZo0SW3atNGgQYP09ttvKzY2VocOHVKTJk20adMmTZ48Wd27d9fdd98t6Y9AO2DAAP3zn//UbbfdpmbNmmnbtm1atGjRNdXapEkTbdiwQf/5z38UGhoqf39/1a9fXy1btlTPnj3VtGlTVa1aVUlJSfrggw/KJLwCPP0EmP89/bR9+/Yit/fo0eOqTz/NmDHDtG7d2gQGBhofHx9Tq1Yt8+ijj5pDhw457TdhwgQTFhZmypUrZySZ9evXG2P+eHrmtddeM/Xq1TPe3t4mMDDQDBgwwKSmpjrtX1BQYF555RVTs2ZN4+PjY5o2bWo+++wz06xZM6cnl6705FBubq4ZO3asqVGjhqlQoYK5/fbbzSeffGJiY2Od5nnhSZnp06c77X+5sa/2OV7sk08+MS1btjQVKlQwfn5+plOnTubrr78u1nGu5tKnn4wx5syZM2b8+PEmIiLCeHt7m9DQUPPkk0+a48ePO+174emnS+uoVKmSueeee8zp06eNMcZs3LjR9OjRw1SrVs14e3ubGjVqmB49ejjVWlQdxvzvc7r0KbjL+fTTT02PHj3MLbfcYry8vEzVqlVNhw4dzJw5c0xubq6jX2ZmpnniiSdMaGio8fLyMhEREWbChAnm7NmzTuNlZWWZoUOHmuDgYOPn52d69eplDh06dNmnn4pTf2JiomnTpo2pWLGi05N4zz33nImOjjZVq1Y1drvd3HrrreaZZ54xGRkZxZo7UBI2Y4pxsRaAR0tOTlaDBg00ceJEPf/88+4uBwDcglAD3GB2796txYsXq3Xr1qpcubIOHDigadOmKTs7W/v27XPJTaoAcCPinhrgBuPn56cdO3Zo7ty5OnHihAICAhQTE6NXX32VQAPgpsaZGgAAYAk80g0AACyBUAMAACyBUAMAACzB8jcKFxQU6Ndff5W/v3+RPxcPAAA8jzFGJ0+eVFhYWLF/WNTyoebXX39VeHi4u8sAAAClkJqaqpo1axarr+VDjb+/v6Q/PpTKlSu7uRoAAFAc2dnZCg8Pd/w9XhyWDzUXLjlVrlyZUAMAwA2mJLeOcKMwAACwBEINAACwBEINAACwBEINAACwBEINAACwBEINAACwBEINAACwBEINAACwBEINAACwBEINAACwBEINAACwBEINAACwBEINAACwBEINAACwBC93F4CipaSkKCMjo0zGDgwMVK1atcpkbAAA3IVQ44FSUlJUv0FDnT1zukzGr+BbUQe+TyLYAAAshVDjgTIyMnT2zGlV7zlG3tXDXTp2XmaqMj+boYyMDEINAMBSCDUezLt6uOwhddxdBgAANwRuFAYAAJZAqAEAAJZAqAEAAJZAqAEAAJbg1lAze/ZsNW3aVJUrV1blypXVqlUrffHFF47txhjFxcUpLCxMvr6+iomJ0f79+91YMQAA8FRuDTU1a9bU1KlTtWPHDu3YsUMdO3bUfffd5wgu06ZN08yZM/XWW29p+/btCgkJUefOnXXy5El3lg0AADyQW0NNr1691L17d9WrV0/16tXTq6++qkqVKmnr1q0yxmjWrFl64YUX1LdvX0VFRWn+/Pk6ffq0Fi1a5M6yAQCAB/KYe2ry8/O1ZMkS5eTkqFWrVkpOTlZaWpq6dOni6GO329W+fXtt3rz5suPk5uYqOzvbaQEAANbn9lCzd+9eVapUSXa7XU888YSWL1+uRo0aKS0tTZIUHBzs1D84ONixrShTpkxRQECAYwkPd+0v8gIAAM/k9lBTv359JSYmauvWrXryyScVGxur7777zrHdZrM59TfGFGq72IQJE5SVleVYUlNTy6x2AADgOdz+mgQfHx/VqfPHqwCio6O1fft2vf766xo/frwkKS0tTaGhoY7+6enphc7eXMxut8tut5dt0QAAwOO4/UzNpYwxys3NVWRkpEJCQpSQkODYdu7cOW3cuFGtW7d2Y4UAAMATufVMzfPPP69u3bopPDxcJ0+e1JIlS7RhwwatXLlSNptNo0aN0uTJk1W3bl3VrVtXkydPVsWKFfXQQw+5s2wAAOCB3BpqfvvtNw0cOFBHjx5VQECAmjZtqpUrV6pz586SpHHjxunMmTMaNmyYjh8/rpYtW2r16tXy9/d3Z9kAAMADuTXUzJ0794rbbTab4uLiFBcXd30KAgAANyyPu6cGAACgNAg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAEgg1AADAErzcXQDcIykpyeVj5ubmym63u3xcSQoMDFStWrXKZGwAgDUQam4y+aeOSzabBgwY4PrBbeUkU+D6cSVV8K2oA98nEWwAAJdFqLnJFOSekoxR9Z5j5F093GXjnvl5h7K+WujycSUpLzNVmZ/NUEZGBqEGAHBZhJqblHf1cNlD6rhsvLzM1DIZFwCA4uJGYQAAYAmEGgAAYAmEGgAAYAmEGgAAYAmEGgAAYAmEGgAAYAmEGgAAYAmEGgAAYAmEGgAAYAmEGgAAYAmEGgAAYAmEGgAAYAmEGgAAYAmEGgAAYAmEGgAAYAmEGgAAYAluDTVTpkzRHXfcIX9/fwUFBal37946cOCAU5/BgwfLZrM5LXfddZebKgYAAJ7KraFm48aNGj58uLZu3aqEhASdP39eXbp0UU5OjlO/e+65R0ePHnUs//3vf91UMQAA8FRe7jz4ypUrndbj4+MVFBSknTt3ql27do52u92ukJCQ610eAAC4gXjUPTVZWVmSpGrVqjm1b9iwQUFBQapXr54ee+wxpaenX3aM3NxcZWdnOy0AAMD6PCbUGGM0evRotW3bVlFRUY72bt266cMPP9S6des0Y8YMbd++XR07dlRubm6R40yZMkUBAQGOJTw8/HpNAQAAuJFbLz9dbMSIEdqzZ482bdrk1N6/f3/HP0dFRSk6OloRERH6/PPP1bdv30LjTJgwQaNHj3asZ2dnE2wAALgJeESoeeqpp7RixQp9+eWXqlmz5hX7hoaGKiIiQgcPHixyu91ul91uL4syAQCAB3NrqDHG6KmnntLy5cu1YcMGRUZGXnWfzMxMpaamKjQ09DpUCAAAbhRuvadm+PDhWrhwoRYtWiR/f3+lpaUpLS1NZ86ckSSdOnVKY8eO1ZYtW3To0CFt2LBBvXr1UmBgoPr06ePO0gEAgIdx65ma2bNnS5JiYmKc2uPj4zV48GCVL19ee/fu1YIFC3TixAmFhoaqQ4cOWrp0qfz9/d1QMQAA8FRuv/x0Jb6+vlq1atV1qgYAANzIPOaRbgAAgGtBqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJZAqAEAAJbg5e4CgOJKSkpy+ZiBgYGqVauWy8cFAFx/hBp4vPxTxyWbTQMGDHD52BV8K+rA90kEGwCwAEINPF5B7inJGFXvOUbe1cNdNm5eZqoyP5uhjIwMQg0AWAChBjcM7+rhsofUcXcZAAAPxY3CAADAEgg1AADAEgg1AADAEgg1AADAEtwaaqZMmaI77rhD/v7+CgoKUu/evXXgwAGnPsYYxcXFKSwsTL6+voqJidH+/fvdVDEAAPBUbg01Gzdu1PDhw7V161YlJCTo/Pnz6tKli3Jychx9pk2bppkzZ+qtt97S9u3bFRISos6dO+vkyZNurBwAAHgatz7SvXLlSqf1+Ph4BQUFaefOnWrXrp2MMZo1a5ZeeOEF9e3bV5I0f/58BQcHa9GiRXr88cfdUTYAAPBAHnVPTVZWliSpWrVqkqTk5GSlpaWpS5cujj52u13t27fX5s2b3VIjAADwTB7z43vGGI0ePVpt27ZVVFSUJCktLU2SFBwc7NQ3ODhYhw8fLnKc3Nxc5ebmOtazs7PLqGIAAOBJPOZMzYgRI7Rnzx4tXry40Dabzea0bowp1HbBlClTFBAQ4FjCw133s/oAAMBzeUSoeeqpp7RixQqtX79eNWvWdLSHhIRI+t8ZmwvS09MLnb25YMKECcrKynIsqampZVc4AADwGG4NNcYYjRgxQsuWLdO6desUGRnptD0yMlIhISFKSEhwtJ07d04bN25U69atixzTbrercuXKTgsAALA+t95TM3z4cC1atEiffvqp/P39HWdkAgIC5OvrK5vNplGjRmny5MmqW7eu6tatq8mTJ6tixYp66KGH3Fk6AADwMG4NNbNnz5YkxcTEOLXHx8dr8ODBkqRx48bpzJkzGjZsmI4fP66WLVtq9erV8vf3v87VAgAAT+bWUGOMuWofm82muLg4xcXFlX1BAADghuURNwoDAABcK0INAACwBEINAACwhFKFmuTkZFfXAQAAcE1KFWrq1KmjDh06aOHChTp79qyrawIAACixUoWa3bt3q3nz5hozZoxCQkL0+OOPa9u2ba6uDQAAoNhKFWqioqI0c+ZMHTlyRPHx8UpLS1Pbtm3VuHFjzZw5U7///rur6wQAALiia7pR2MvLS3369NG//vUvvfbaa/rpp580duxY1axZU4MGDdLRo0ddVScAAMAVXVOo2bFjh4YNG6bQ0FDNnDlTY8eO1U8//aR169bpyJEjuu+++1xVJwAAwBWV6heFZ86cqfj4eB04cEDdu3fXggUL1L17d5Ur90dGioyM1LvvvqsGDRq4tFgAAIDLKVWomT17toYMGaJHHnlEISEhRfapVauW5s6de03FAQAAFFepQs3Bgwev2sfHx0exsbGlGR4AAKDESnVPTXx8vD766KNC7R999JHmz59/zUUBAACUVKlCzdSpUxUYGFioPSgoSJMnT77mogAAAEqqVKHm8OHDioyMLNQeERGhlJSUay4KAACgpEoVaoKCgrRnz55C7bt371b16tWvuSgAAICSKlWoeeCBB/T0009r/fr1ys/PV35+vtatW6eRI0fqgQcecHWNAAAAV1Wqp59eeeUVHT58WJ06dZKX1x9DFBQUaNCgQdxTAwAA3KJUocbHx0dLly7Vyy+/rN27d8vX11dNmjRRRESEq+sDAAAollKFmgvq1aunevXquaoWAACAUitVqMnPz9e8efO0du1apaenq6CgwGn7unXrXFIcAABAcZUq1IwcOVLz5s1Tjx49FBUVJZvN5uq6AAAASqRUoWbJkiX617/+pe7du7u6HgAAgFIp1SPdPj4+qlOnjqtrAQAAKLVShZoxY8bo9ddflzHG1fUAAACUSqkuP23atEnr16/XF198ocaNG8vb29tp+7Jly1xSHAAAQHGVKtRUqVJFffr0cXUtAAAApVaqUBMfH+/qOgAAAK5Jqe6pkaTz589rzZo1evfdd3Xy5ElJ0q+//qpTp065rDgAAIDiKtWZmsOHD+uee+5RSkqKcnNz1blzZ/n7+2vatGk6e/as5syZ4+o6AQAArqhUZ2pGjhyp6OhoHT9+XL6+vo72Pn36aO3atS4rDgAAoLhK/fTT119/LR8fH6f2iIgIHTlyxCWFAQAAlESpztQUFBQoPz+/UPsvv/wif3//ay4KAACgpEoVajp37qxZs2Y51m02m06dOqWJEyfy6gQAAOAWpbr89P/+3/9Thw4d1KhRI509e1YPPfSQDh48qMDAQC1evNjVNQIAAFxVqUJNWFiYEhMTtXjxYu3atUsFBQV69NFH9fDDDzvdOAwAAHC9lCrUSJKvr6+GDBmiIUOGuLIeAACAUilVqFmwYMEVtw8aNKhUxQAAAJRWqULNyJEjndbz8vJ0+vRp+fj4qGLFioQaAABw3ZXq6afjx487LadOndKBAwfUtm1bbhQGAABuUep3P12qbt26mjp1aqGzOAAAANeDy0KNJJUvX16//vqrK4cEAAAollLdU7NixQqndWOMjh49qrfeektt2rRxSWEAAAAlUapQ07t3b6d1m82mW265RR07dtSMGTNcURcAAECJlCrUFBQUuLoOAACAa+LSe2oAAADcpVRnakaPHl3svjNnzrzsti+//FLTp0/Xzp07dfToUS1fvtzp0tbgwYM1f/58p31atmyprVu3lrhmAABgbaUKNd9++6127dql8+fPq379+pKkH374QeXLl9ftt9/u6Gez2a44Tk5Ojpo1a6ZHHnlE999/f5F97rnnHsXHxzvWfXx8SlMyAACwuFKFml69esnf31/z589X1apVJf3xg3yPPPKI/vznP2vMmDHFGqdbt27q1q3bFfvY7XaFhISUpkwAAHATKdU9NTNmzNCUKVMcgUaSqlatqldeecXlTz9t2LBBQUFBqlevnh577DGlp6dfsX9ubq6ys7OdFgAAYH2lCjXZ2dn67bffCrWnp6fr5MmT11zUBd26ddOHH36odevWacaMGdq+fbs6duyo3Nzcy+4zZcoUBQQEOJbw8HCX1QMAADxXqUJNnz599Mgjj+jf//63fvnlF/3yyy/697//rUcffVR9+/Z1WXH9+/dXjx49FBUVpV69eumLL77QDz/8oM8///yy+0yYMEFZWVmOJTU11WX1AAAAz1Wqe2rmzJmjsWPHasCAAcrLy/tjIC8vPfroo5o+fbpLC7xYaGioIiIidPDgwcv2sdvtstvtZVYDAADwTKUKNRUrVtQ777yj6dOn66effpIxRnXq1JGfn5+r63OSmZmp1NRUhYaGlulxAADAjeeafnzv6NGjOnr0qOrVqyc/Pz8ZY0q0/6lTp5SYmKjExERJUnJyshITE5WSkqJTp05p7Nix2rJliw4dOqQNGzaoV69eCgwMVJ8+fa6lbAAAYEGlCjWZmZnq1KmT6tWrp+7du+vo0aOSpKFDhxb7cW5J2rFjh5o3b67mzZtL+uNH/Zo3b66///3vKl++vPbu3av77rtP9erVU2xsrOrVq6ctW7bI39+/NGUDAAALK9Xlp2eeeUbe3t5KSUlRw4YNHe39+/fXM888U+zHumNiYq54dmfVqlWlKQ8AANyEShVqVq9erVWrVqlmzZpO7XXr1tXhw4ddUhgAAEBJlOryU05OjipWrFioPSMjgyePAACAW5Qq1LRr104LFixwrNtsNhUUFGj69Onq0KGDy4oDAAAorlJdfpo+fbpiYmK0Y8cOnTt3TuPGjdP+/ft17Ngxff31166uEQAA4KpKFWoaNWqkPXv2aPbs2SpfvrxycnLUt29fDR8+nN+QwQ0nKSmpTMYNDAxUrVq1ymRsAEBhJQ41eXl56tKli959911NmjSpLGoCrov8U8clm00DBgwok/Er+FbUge+TCDYAcJ2UONR4e3tr3759stlsZVEPcN0U5J6SjFH1nmPkXd21Lz7Ny0xV5mczlJGRQagBgOukVJefBg0apLlz52rq1Kmurge47ryrh8seUsfdZQAArlGpQs25c+f0/vvvKyEhQdHR0YXe+TRz5kyXFAcAAFBcJQo1P//8s2rXrq19+/bp9ttvlyT98MMPTn24LAUAANyhRKGmbt26Onr0qNavXy/pj9civPHGGwoODi6T4gAAAIqrRD++d+l7mr744gvl5OS4tCAAAIDSKNUvCl9wpZdRAgAAXE8lCjU2m63QPTPcQwMAADxBie6pMcZo8ODBjpdWnj17Vk888UShp5+WLVvmugoBAACKoUShJjY21mm9rH6JFQAAoKRKFGri4+PLqg4AAIBrck03CgMAAHgKQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEQg0AALAEt4aaL7/8Ur169VJYWJhsNps++eQTp+3GGMXFxSksLEy+vr6KiYnR/v373VMsAADwaG4NNTk5OWrWrJneeuutIrdPmzZNM2fO1FtvvaXt27crJCREnTt31smTJ69zpQAAwNN5ufPg3bp1U7du3YrcZozRrFmz9MILL6hv376SpPnz5ys4OFiLFi3S448/fj1LBQAAHs6toeZKkpOTlZaWpi5dujja7Ha72rdvr82bN1821OTm5io3N9exnp2dXea1ApeTlJTk8jEDAwNVq1Ytl48LADc6jw01aWlpkqTg4GCn9uDgYB0+fPiy+02ZMkWTJk0q09qAq8k/dVyy2TRgwACXj13Bt6IOfJ9EsAGAS3hsqLnAZrM5rRtjCrVdbMKECRo9erRjPTs7W+Hh4WVWH1CUgtxTkjGq3nOMvKu77t+/vMxUZX42QxkZGYQaALiEx4aakJAQSX+csQkNDXW0p6enFzp7czG73S673V7m9QHF4V09XPaQOu4uAwBuCh77OzWRkZEKCQlRQkKCo+3cuXPauHGjWrdu7cbKAACAJ3LrmZpTp07pxx9/dKwnJycrMTFR1apVU61atTRq1ChNnjxZdevWVd26dTV58mRVrFhRDz30kBurBgAAnsitoWbHjh3q0KGDY/3CvTCxsbGaN2+exo0bpzNnzmjYsGE6fvy4WrZsqdWrV8vf399dJQMAAA/l1lATExMjY8xlt9tsNsXFxSkuLu76FQUAAG5IHntPDQAAQEkQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCV4dKiJi4uTzWZzWkJCQtxdFgAA8EBe7i7gaho3bqw1a9Y41suXL+/GagAAgKfy+FDj5eXF2RkAAHBVHn35SZIOHjyosLAwRUZG6oEHHtDPP/98xf65ubnKzs52WgAAgPV5dKhp2bKlFixYoFWrVukf//iH0tLS1Lp1a2VmZl52nylTpiggIMCxhIeHX8eKAQCAu3h0qOnWrZvuv/9+NWnSRHfffbc+//xzSdL8+fMvu8+ECROUlZXlWFJTU69XuQAAwI08/p6ai/n5+alJkyY6ePDgZfvY7XbZ7fbrWBUAAPAEHn2m5lK5ublKSkpSaGiou0sBAAAexqNDzdixY7Vx40YlJyfrm2++Ub9+/ZSdna3Y2Fh3lwYAADyMR19++uWXX/Tggw8qIyNDt9xyi+666y5t3bpVERER7i4NAAB4GI8ONUuWLHF3CQAA4Abh0ZefAAAAiotQAwAALIFQAwAALMGj76m5EaSkpCgjI8OlYyYlJbl0PAAAbgaEmmuQkpKi+g0a6uyZ0+4uBQCAmx6h5hpkZGTo7JnTqt5zjLyru+4dU2d+3qGsrxa6bDwAAG4GhBoX8K4eLntIHZeNl5fJ+6oAACgpbhQGAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACW4OXuAgCUXFJSUpmMm5ubK7vd7vJxAwMDVatWLZePCwAXI9QAN5D8U8clm00DBgwomwPYykmmwOXDVvCtqAPfJxFsAJQpQg1wAynIPSUZo+o9x8i7erhLxz7z8w5lfbXQ5WPnZaYq87MZysjIINQAKFOEGuAG5F09XPaQOi4dMy8ztczGBoDrgRuFAQCAJRBqAACAJRBqAACAJRBqAACAJRBqAACAJRBqAACAJRBqAACAJfA7NQCui7J6tQOvYLg+UlJSlJGRUSZj8x1eH2X1HXrS90eoAVCmyvrVDryCoeylpKSofoOGOnvmdJmMz3dY9sryO/Sk749QA6BMleWrHXgFw/WRkZGhs2dO8x3ewMrqO/S0749QA+C64PULNz6+wxuf1b9DbhQGAACWQKgBAACWQKgBAACWQKgBAACWcEOEmnfeeUeRkZGqUKGCWrRooa+++srdJQEAAA/j8aFm6dKlGjVqlF544QV9++23+vOf/6xu3bopJSXF3aUBAAAP4vGhZubMmXr00Uc1dOhQNWzYULNmzVJ4eLhmz57t7tIAAIAH8ehQc+7cOe3cuVNdunRxau/SpYs2b97spqoAAIAn8ugf38vIyFB+fr6Cg4Od2oODg5WWllbkPrm5ucrNzXWsZ2VlSZKys7NdXt+pU6f+OGbajyo4d9Zl4+ZlppbJuGU5NjVfn7Gp+ZKxj/0iSdq5c6fjz6MrlStXTgUFBTfMuGU19oEDByTdeN/hjfY5l+W4ZfUdXvj+Tp065fK/Zy+MZ4wp/k7Ggx05csRIMps3b3Zqf+WVV0z9+vWL3GfixIlGEgsLCwsLC4sFltTU1GLnBo8+UxMYGKjy5csXOiuTnp5e6OzNBRMmTNDo0aMd6wUFBTp27JiqV68um81WqH92drbCw8OVmpqqypUru3YCHuZmmevNMk/p5pnrzTJPibla0c0yT8m1czXG6OTJkwoLCyv2Ph4danx8fNSiRQslJCSoT58+jvaEhATdd999Re5jt9tlt9ud2qpUqXLVY1WuXNny/7JdcLPM9WaZp3TzzPVmmafEXK3oZpmn5Lq5BgQElKi/R4caSRo9erQGDhyo6OhotWrVSu+9955SUlL0xBNPuLs0AADgQTw+1PTv31+ZmZl66aWXdPToUUVFRem///2vIiIi3F0aAADwIB4faiRp2LBhGjZsWJmMbbfbNXHixEKXrKzoZpnrzTJP6eaZ680yT4m5WtHNMk/J/XO1GVOSZ6UAAAA8k0f/+B4AAEBxEWoAAIAlEGoAAIAlEGoAAIAl3PSh5p133lFkZKQqVKigFi1a6KuvvnJ3SQ5ffvmlevXqpbCwMNlsNn3yySdO240xiouLU1hYmHx9fRUTE6P9+/c79cnNzdVTTz2lwMBA+fn56d5779Uvv/zi1Of48eMaOHCgAgICFBAQoIEDB+rEiRNOfVJSUtSrVy/5+fkpMDBQTz/9tM6dO+eSeU6ZMkV33HGH/P39FRQUpN69ezveU2K1uc6ePVtNmzZ1/DBVq1at9MUXX1hunpeaMmWKbDabRo0aZbm5xsXFyWazOS0hISGWm6ckHTlyRAMGDFD16tVVsWJF/elPf9LOnTstN9fatWsX+k5tNpuGDx9uqXlK0vnz5/V///d/ioyMlK+vr2699Va99NJLTu+fuqHmW/I3MlnHkiVLjLe3t/nHP/5hvvvuOzNy5Ejj5+dnDh8+7O7SjDHG/Pe//zUvvPCC+fjjj40ks3z5cqftU6dONf7+/ubjjz82e/fuNf379zehoaEmOzvb0eeJJ54wNWrUMAkJCWbXrl2mQ4cOplmzZub8+fOOPvfcc4+JiooymzdvNps3bzZRUVGmZ8+eju3nz583UVFRpkOHDmbXrl0mISHBhIWFmREjRrhknl27djXx8fFm3759JjEx0fTo0cPUqlXLnDp1ynJzXbFihfn888/NgQMHzIEDB8zzzz9vvL29zb59+yw1z4tt27bN1K5d2zRt2tSMHDnS0W6VuU6cONE0btzYHD161LGkp6dbbp7Hjh0zERERZvDgweabb74xycnJZs2aNebHH3+03FzT09Odvs+EhAQjyaxfv95S8zTmj3cpVq9e3Xz22WcmOTnZfPTRR6ZSpUpm1qxZjj430nxv6lBz5513mieeeMKprUGDBua5555zU0WXd2moKSgoMCEhIWbq1KmOtrNnz5qAgAAzZ84cY4wxJ06cMN7e3mbJkiWOPkeOHDHlypUzK1euNMYY89133xlJZuvWrY4+W7ZsMZLM999/b4z5I1yVK1fOHDlyxNFn8eLFxm63m6ysLJfPNT093UgyGzdutPxcjTGmatWq5v3337fkPE+ePGnq1q1rEhISTPv27R2hxkpznThxomnWrFmR26w0z/Hjx5u2bdtedruV5nqpkSNHmttuu80UFBRYbp49evQwQ4YMcWrr27evGTBggDHmxvteb9rLT+fOndPOnTvVpUsXp/YuXbpo8+bNbqqq+JKTk5WWluZUv91uV/v27R3179y5U3l5eU59wsLCFBUV5eizZcsWBQQEqGXLlo4+d911lwICApz6REVFOb1UrGvXrsrNzXU69ewqWVlZkqRq1apZeq75+flasmSJcnJy1KpVK0vOc/jw4erRo4fuvvtup3arzfXgwYMKCwtTZGSkHnjgAf3888+Wm+eKFSsUHR2tv/zlLwoKClLz5s31j3/8w7HdSnO92Llz57Rw4UINGTJENpvNcvNs27at1q5dqx9++EGStHv3bm3atEndu3eXdON9rzfELwqXhYyMDOXn5xd623dwcHCht4J7ogs1FlX/4cOHHX18fHxUtWrVQn0u7J+WlqagoKBC4wcFBTn1ufQ4VatWlY+Pj8s/K2OMRo8erbZt2yoqKspx/At1XzqPG3Gue/fuVatWrXT27FlVqlRJy5cvV6NGjRx/sK0yzyVLlmjXrl3avn17oW1W+k5btmypBQsWqF69evrtt9/0yiuvqHXr1tq/f7+l5vnzzz9r9uzZGj16tJ5//nlt27ZNTz/9tOx2uwYNGmSpuV7sk08+0YkTJzR48GDHsS/UfOkcbsR5jh8/XllZWWrQoIHKly+v/Px8vfrqq3rwwQcdNVyo/dK5eOJ8b9pQc4HNZnNaN8YUavNkpan/0j5F9S9NH1cYMWKE9uzZo02bNhXaZpW51q9fX4mJiTpx4oQ+/vhjxcbGauPGjZc9/o04z9TUVI0cOVKrV69WhQoVLtvPCnPt1q2b45+bNGmiVq1a6bbbbtP8+fN11113FXn8G3GeBQUFio6O1uTJkyVJzZs31/79+zV79mwNGjTosjXciHO92Ny5c9WtWzenswdFHf9GnefSpUu1cOFCLVq0SI0bN1ZiYqJGjRqlsLAwxcbGXrYOT53vTXv5KTAwUOXLly+U/tLT0wslRU904emKK9UfEhKic+fO6fjx41fs89tvvxUa//fff3fqc+lxjh8/rry8PJd+Vk899ZRWrFih9evXq2bNmo52q83Vx8dHderUUXR0tKZMmaJmzZrp9ddft9Q8d+7cqfT0dLVo0UJeXl7y8vLSxo0b9cYbb8jLy8txDCvM9VJ+fn5q0qSJDh48aKnvNDQ0VI0aNXJqa9iwoVJSUhzHl6wx1wsOHz6sNWvWaOjQoY42q83z2Wef1XPPPacHHnhATZo00cCBA/XMM89oypQpjhqkG2e+N22o8fHxUYsWLZSQkODUnpCQoNatW7upquKLjIxUSEiIU/3nzp3Txo0bHfW3aNFC3t7eTn2OHj2qffv2Ofq0atVKWVlZ2rZtm6PPN998o6ysLKc++/bt09GjRx19Vq9eLbvdrhYtWlzzXIwxGjFihJYtW6Z169YpMjLSsnMtijFGubm5lppnp06dtHfvXiUmJjqW6OhoPfzww0pMTNStt95qmbleKjc3V0lJSQoNDbXUd9qmTZtCP7Xwww8/KCIiQpI1/5zGx8crKChIPXr0cLRZbZ6nT59WuXLOUaB8+fKOR7pvuPkW63Zii7rwSPfcuXPNd999Z0aNGmX8/PzMoUOH3F2aMeaPJ0e+/fZb8+233xpJZubMmebbb791PHI+depUExAQYJYtW2b27t1rHnzwwSIfs6tZs6ZZs2aN2bVrl+nYsWORj9k1bdrUbNmyxWzZssU0adKkyMfsOnXqZHbt2mXWrFljatas6bLHCp988kkTEBBgNmzY4PQY5enTpx19rDLXCRMmmC+//NIkJyebPXv2mOeff96UK1fOrF692lLzLMrFTz9Zaa5jxowxGzZsMD///LPZunWr6dmzp/H393f8d8Qq89y2bZvx8vIyr776qjl48KD58MMPTcWKFc3ChQsdfawyV2OMyc/PN7Vq1TLjx48vtM1K84yNjTU1atRwPNK9bNkyExgYaMaNG3dDzvemDjXGGPP222+biIgI4+PjY26//XbHY8SeYP369UZSoSU2NtYY88ejdhMnTjQhISHGbrebdu3amb179zqNcebMGTNixAhTrVo14+vra3r27GlSUlKc+mRmZpqHH37Y+Pv7G39/f/Pwww+b48ePO/U5fPiw6dGjh/H19TXVqlUzI0aMMGfPnnXJPIuaoyQTHx/v6GOVuQ4ZMsTx79stt9xiOnXq5Ag0VppnUS4NNVaZ64Xf7PD29jZhYWGmb9++Zv/+/ZabpzHG/Oc//zFRUVHGbrebBg0amPfee89pu5XmumrVKiPJHDhwoNA2K80zOzvbjBw50tSqVctUqFDB3HrrreaFF14wubm5N+R8bcYYU7xzOgAAAJ7rpr2nBgAAWAuhBgAAWAKhBgAAWAKhBgAAWAKhBgAAWAKhBgAAWAKhBgAAWAKhBoDL2Ww2ffLJJ+4uA8BNhlADoBCbzXbFZfDgwe4usUhpaWl66qmndOutt8putys8PFy9evXS2rVrr3stBDvg+vNydwEAPM/FL5RbunSp/v73vzu9zNDX19cdZV3RoUOH1KZNG1WpUkXTpk1T06ZNlZeXp1WrVmn48OH6/vvv3V0igDLGmRoAhYSEhDiWgIAA2Ww2p7ZFixbptttuk4+Pj+rXr68PPvjgiuO99NJLCg4OVmJioiRp8+bNateunXx9fRUeHq6nn35aOTk5jv61a9fW5MmTNWTIEPn7+6tWrVp67733rniMYcOGyWazadu2berXr5/q1aunxo0ba/To0dq6daujX0pKiu677z5VqlRJlStX1l//+lf99ttvju2DBw9W7969ncYeNWqUYmJiHOsxMTF6+umnNW7cOFWrVk0hISGKi4tzql+S+vTpI5vN5lgHULYINQBKZPny5Ro5cqTGjBmjffv26fHHH9cjjzyi9evXF+prjNHIkSM1d+5cbdq0SX/605+0d+9ede3aVX379tWePXu0dOlSbdq0SSNGjHDad8aMGYqOjta3336rYcOG6cknn7zs2ZZjx45p5cqVGj58uPz8/Aptr1KliqOe3r1769ixY9q4caMSEhL0008/qX///iX+HObPny8/Pz998803mjZtml566SUlJCRIkrZv3y5Jio+P19GjRx3rAMpYyd7nCeBmEx8fbwICAhzrrVu3No899phTn7/85S+me/fujnVJ5qOPPjIDBgwwDRo0MKmpqY5tAwcONH/729+c9v/qq69MuXLlzJkzZ4wxxkRERJgBAwY4thcUFJigoCAze/bsImv85ptvjCSzbNmyK85l9erVpnz58k5vD96/f7+RZLZt22aMMSY2Ntbcd999TvuNHDnStG/f3rHevn1707ZtW6c+d9xxhxk/frzTZ7B8+fIr1gPAtThTA6BEkpKS1KZNG6e2Nm3aKCkpyantmWee0ZYtW/TVV1+pZs2ajvadO3dq3rx5qlSpkmPp2rWrCgoKlJyc7OjXtGlTxz9fuPyVnp5eZE3GGEe/q9UeHh6u8PBwR1ujRo1UpUqVQvVfzcX1SVJoaOhl6wNwfRBqAJTYpeHBGFOorXPnzjpy5IhWrVrl1F5QUKDHH39ciYmJjmX37t06ePCgbrvtNkc/b2/vQscsKCgosp66devKZrNdNZgUVeel7eXKlXOEpAvy8vIK7VOS+gBcH4QaACXSsGFDbdq0yalt8+bNatiwoVPbvffeq0WLFmno0KFasmSJo/3222/X/v37VadOnUKLj49PqWqqVq2aunbtqrffftvphuMLTpw4IemPszIpKSlKTU11bPvuu++UlZXlqP+WW25xevpLkuMG55Lw9vZWfn5+ifcDUHqEGgAl8uyzz2revHmaM2eODh48qJkzZ2rZsmUaO3Zsob59+vTRBx98oEceeUT//ve/JUnjx4/Xli1bNHz4cCUmJurgwYNasWKFnnrqqWuq65133lF+fr7uvPNOffzxxzp48KCSkpL0xhtvqFWrVpKku+++W02bNtXDDz+sXbt2adu2bRo0aJDat2+v6OhoSVLHjh21Y8cOLViwQAcPHtTEiRO1b9++EtdTu3ZtrV27VmlpaTp+/Pg1zQ1A8RBqAJRI79699frrr2v69Olq3Lix3n33XcXHxzs98nyxfv36af78+Ro4cKCWLVumpk2bauPGjTp48KD+/Oc/q3nz5nrxxRcVGhp6TXVFRkZq165d6tChg8aMGaOoqCh17txZa9eu1ezZsyX97wfxqlatqnbt2unuu+/WrbfeqqVLlzrG6dq1q1588UWNGzdOd9xxh06ePKlBgwaVuJ4ZM2YoISFB4eHhat68+TXNDUDx2MylF48BAABuQJypAQAAlkCoAQAAlkCoAQAAlkCoAQAAlkCoAQAAlkCoAQAAlkCoAQAAlkCoAQAAlkCoAQAAlkCoAQAAlkCoAQAAlkCoAQAAlvD/AUv4e4ja65HFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(num_tokens, bins=20, edgecolor='black')\n",
    "plt.xlabel('Token Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Token Counts')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most papers seem to contain somewhere between **5_000** to **30_000** tokens. And as for number of paragraphs — if we split on `\".\\n\"` we will get something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(paper_paths[0], 'r') as fp:\n",
    "    paper = fp.read()\n",
    "\n",
    "paper_chunks = paper.split(\"\\n\")\n",
    "len(paper_chunks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper contains `86` 'paragraphs' in total. We will iteratively add these together until exceeding the limit of `650` tokens decided earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 650\n",
    "\n",
    "for i in range(len(paper_chunks)):\n",
    "    chunk = \".\\n\".join(paper_chunks[:i-1])\n",
    "    if len(tokenizer.encode(\"\\n\".join(paper_chunks[:i]))) > max_tokens:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring Semantic Perturbations on Grover.\n",
      "CMSC 473/673: Capstone in Machine Learning.\n",
      "Ziqing Ji, Pranav Kulkarni, Marko Neskovic, Kevin Nolan, Yan Xu.\n",
      "21 December 2021.\n",
      "https://github.com/itspranavk/cmsc473fall21-grover.\n",
      "Abstract.\n",
      "With news and information being as easy to access as they currently are, it is more important than ever to.\n",
      "ensure that people are not mislead by what they read. Recently, the rise of neural fake news (AI-generated fake.\n",
      "news) and its demonstrated e\u000bectiveness at fooling humans has prompted the development of models to detect.\n",
      "it. One such model is the Grover model, which can both detect neural fake news to prevent it, and generate it to.\n",
      "demonstrate how a model could be misused to fool human readers. In this work we explore the Grover model's.\n",
      "fake news detection capabilities by performing targeted attacks through perturbations on input news articles..\n",
      "Through this we test Grover's resilience to these adversarial attacks and expose some potential vulnerabilities.\n",
      "which should be addressed in further iterations to ensure it can detect all types of fake news accurately..\n",
      "1 Introduction and Literature.\n",
      "1.1 The Rise of Machine-Generated Fake News.\n",
      "While the term \\fake news\" has become politically charged in recent years, researchers of online misinformation.\n",
      "typically de\fne it as a form of propaganda that knowingly transmits false information to readers, viewers, or users.\n",
      "[2]. This de\fnition is rather broad, with many academics o\u000bering their own take. Alcott and Gentzkow describe.\n",
      "fake news as \\news articles that are intentionally and veri\fably false, and could mislead readers\" [1]. Wardle and.\n",
      "Derakhshan posit seven categories of fake news, which together make a scale ranging from simple satire to fully.\n",
      "fabricated content [13]. For the purposes of this project, we will de\fne fake news as any text that is created with the.\n",
      "intention of imparting false information onto the reader to achieve the goal of the disseminator. This includes, as.\n",
      "Zellers et Al. describe, \\targeted propaganda that closely mimics the style of real news\" [16]. Taken this way, fake.\n",
      "news has been present in social and political discourse for thousands of years. In one of the earliest cited examples.\n",
      "of fake news, Ramses the Great of Ancient Egypt spread propaganda portraying the Battle of Kadesh as a glowing.\n",
      "victory for Egypt over the Hittites. The Treaty of Kadesh reveals that in fact, the battle ended in stalemate [14]..\n",
      "In the modern era, fake news can pose great threats in democracy, politics, economy, and so on [5, 1, 12]. Creating.\n",
      "and consuming high quality misinformation is notably easier over the internet compared to print media [11, 1]. The.\n",
      "current deep learning methods in natural language processing [4, 9] can automatically generate texts, and they can\n"
     ]
    }
   ],
   "source": [
    "print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(chunk))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity I won't add overlapping chunks — and I don't think it's too important as we already capture a lot of information.\n",
    "\n",
    "We can confirm the assumption by running this across more chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(paper):\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    for i in range(len(paper_chunks)):\n",
    "        # add the next chunk to the current chunk\n",
    "        current_chunk.append(paper_chunks[i])\n",
    "        if len(tokenizer.encode(\"\\n\".join(current_chunk))) > max_tokens:\n",
    "            # join the current chunks minus the final chunk that pushed us over limit\n",
    "            chunks.append(\"\\n\".join(current_chunk[:-1]))\n",
    "            # reset the current chunk to the final chunk that pushed us over limit\n",
    "            current_chunk = [current_chunk[-1]]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Exploring Semantic Perturbations on Grover\\nCMSC 473/673: Capstone in Machine Learning\\nZiqing Ji, Pranav Kulkarni, Marko Neskovic, Kevin Nolan, Yan Xu\\n21 December 2021\\nhttps://github.com/itspranavk/cmsc473fall21-grover\\nAbstract\\nWith news and information being as easy to access as they currently are, it is more important than ever to\\nensure that people are not mislead by what they read. Recently, the rise of neural fake news (AI-generated fake\\nnews) and its demonstrated e\\x0bectiveness at fooling humans has prompted the development of models to detect\\nit. One such model is the Grover model, which can both detect neural fake news to prevent it, and generate it to\\ndemonstrate how a model could be misused to fool human readers. In this work we explore the Grover model\\'s\\nfake news detection capabilities by performing targeted attacks through perturbations on input news articles.\\nThrough this we test Grover\\'s resilience to these adversarial attacks and expose some potential vulnerabilities\\nwhich should be addressed in further iterations to ensure it can detect all types of fake news accurately.\\n1 Introduction and Literature\\n1.1 The Rise of Machine-Generated Fake News\\nWhile the term \\\\fake news\" has become politically charged in recent years, researchers of online misinformation\\ntypically de\\x0cne it as a form of propaganda that knowingly transmits false information to readers, viewers, or users\\n[2]. This de\\x0cnition is rather broad, with many academics o\\x0bering their own take. Alcott and Gentzkow describe\\nfake news as \\\\news articles that are intentionally and veri\\x0cably false, and could mislead readers\" [1]. Wardle and\\nDerakhshan posit seven categories of fake news, which together make a scale ranging from simple satire to fully\\nfabricated content [13]. For the purposes of this project, we will de\\x0cne fake news as any text that is created with the\\nintention of imparting false information onto the reader to achieve the goal of the disseminator. This includes, as\\nZellers et Al. describe, \\\\targeted propaganda that closely mimics the style of real news\" [16]. Taken this way, fake\\nnews has been present in social and political discourse for thousands of years. In one of the earliest cited examples\\nof fake news, Ramses the Great of Ancient Egypt spread propaganda portraying the Battle of Kadesh as a glowing\\nvictory for Egypt over the Hittites. The Treaty of Kadesh reveals that in fact, the battle ended in stalemate [14].\\nIn the modern era, fake news can pose great threats in democracy, politics, economy, and so on [5, 1, 12]. Creating\\nand consuming high quality misinformation is notably easier over the internet compared to print media [11, 1]. The\\ncurrent deep learning methods in natural language processing [4, 9] can automatically generate texts, and they can',\n",
       " 'be applied to fake news generation, making it harder to tell whether a given article is authentic or fake. This change\\nin ease has caused a dramatic increase in the proliferation of fabricated content using social media [8].\\n1.2 An Algorithmic Response\\nLazer et al. asserted in 2018 that the rise of fake news prompts \\\\a new system of safeguards\" [8]. Social media\\ncompanies have since adopted several strategies to detect and remove fake news from their websites. For obvious\\nreasons, none of these strategies have been made publicly available. However, a good body of research on fake news\\ndetection is accessible to the wider public. Shu et Al. describe fake news detection from a data mining perspective.\\nThey focus more on social engagement, click-through rate, and share counts rather than the actual content of social\\nmedia posts to determine what is legitimate [11]. Reis et Al. created a new system of features and measures for use\\nin supervised learning pertaining to fake news detection [10]. Zhou et al. lay out a multidisciplinary approach in\\nwhich they \\\\broadly adopt techniques in data mining, machine learning, natural language processing, information\\nretrieval, and social search\" [17]. It is clear that there are a plethora of existing techniques to detect and address\\nfake news in social media, but it is uncertain how well these techniques perform on real-world data. Additionally, it\\nis unclear what vulnerabilities they possess. Our proposed paper will examine types of vulnerabilities in Grover, a\\nstate-of-the-art framework for detecting fake news.\\n1arXiv:2302.00509v1  [cs.LG]  1 Feb 20231.3 GPT-2 and Grover\\nIn early 2019, AI research company Open AI released GPT-2, a \\\\large transformer-based language model with 1.5\\nbillion parameters\" [9]. GPT-2 is remarkably good at synthesising new text given a pre\\x0cx. While it still under-\\nperforms human ability, the model has broken algorithmic records in accuracy and perplexity on several datasets.\\nThe incredible accuracy of GPT-2 has led to some concern over its ethical use. Floridi and Chiriatti argue that\\nwith such technology, \\\\Readers and consumers of texts will have to get used to not knowing whether the source\\nis arti\\x0ccial or human\" [18]. Zeller et Al, however, focus on GPT\\'s implications on fake news [16]. They conclude\\nthat GPT-2 and related technologies pose a signi\\x0ccant threat to the validity of online information. The assumption\\nis that GPT is highly capable of creating texts that fool both humans and machines, allowing for an even greater\\nproliferation of fake news on the internet. To counter this threat, Zeller and his team created a state-of-the-art tool\\nnamed Grover. Grover is both a neural fake news generator and detector. It is built using the same architecture as',\n",
       " 'GPT2 [9]. It considers \\x0cve metadata \\x0celds of an article: domain, date, authors, headline, and body. The design of\\nthe model allows for \\nexible decomposition of the joint distribution. During inference, the model uses the \\x0celds as\\ncontext where each \\x0celd contains its content and \\x0celd-speci\\x0cc tokens. The tokens are concatenated and appended\\nwith the target \\x0celd-speci\\x0cc token to generate the target \\x0celd. During training, they separate metadata \\x0celds into\\ntwo sets F1 and F2, where they minimize the cross entropy loss of predicting tokens in F1 followed by F2. As is\\nshown in the experiments, Grover noticeably improves on perplexity when conditioned on metadata, and it is over 5\\nperplexity points lower than GPT2 models. Humans are Easily Fooled by Grover-written propaganda. Also, Grover\\nperforms best at detecting Grover\\'s fake news compared with GPT2, BERT, and FastText [7]. Simple techniques\\naren\\'t enough to consistently fool Grover. For example, rejection sampling produces only a temporary advantage to\\na hypothetical attacker, because once Grover is trained on additional generations from that attacker, its accuracy\\nreturns to levels we expect [15].\\n1.4 Vulnerabilities in Fake News Detection\\nCurrently, there is no substantial research on the robustness of fake news detectors. To \\x0cll this gap, we would like\\nto research the vulnerabilities of Grover, as it is the best-performing detector to date. Speci\\x0ccally, we will design\\nattacks at the word, sentence, paragraph, and article (i.e discourse) level to analyze Grover\\'s performance in detecting\\nfake news. Some attacks include replacing single words with synonyms, rearranging phrases within sentences, and\\nbreaking up the \\\\narrative structure\" of an article. We hope to determine how much and what parts of a text need\\nto be changed before Grover will miscategorize it. In conducting this research, we will provide analysis that can be\\nused to make Grover and similar systems more robust, with the ultimate goal of improving validity in online texts.\\n2 Getting Started\\n2.1 Setting up Grover\\nAs part of Zeller\\'s goal of ensuring transparency in neural fake news detectors and generators, the Grover source\\ncode is publicly available on GitHub here: https://github.com/rowanz/grover\\nHowever, setting up Grover was one of the hardest parts of this project. The version of Grover available on\\nGitHub has numerous inconsistencies and bugs that make it hard to set up and generate useful results. Some of\\nthese issues include:\\n•Inconsistencies between naming conventions. For example, large and medium models, article and text \\x0celds,\\netc.\\n•Given discriminator does not consider article content to classify.\\n•Multiple authors are not supported. Authors must be converted from list to string.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_chunks = chunker(paper)\n",
    "paper_chunks[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These chunks seem reasonable, we will apply this `chunker` function across all of our papers to create a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a644ca300124016a3324e926bcae7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = []\n",
    "\n",
    "for paper_path in tqdm(paper_paths):\n",
    "    doi = paper_path.split('/')[-1][:-4]\n",
    "    with open(paper_path) as f:\n",
    "        paper = f.read()\n",
    "    paper_chunks = chunker(paper)\n",
    "    for i, chunk in enumerate(paper_chunks):\n",
    "        dataset.append({\n",
    "            'doi': doi,\n",
    "            'chunk-id': i,\n",
    "            'chunk': chunk\n",
    "        })\n",
    "len(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that none of these exceed the token limit set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in dataset:\n",
    "    chunk = record['chunk']\n",
    "    if len(tokenizer.encode(chunk)) > max_tokens:\n",
    "        print(f'Chunk too long: {len(tokenizer.encode(chunk))}')\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now save these to file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('dataset.jsonl', 'w') as fp:\n",
    "    for item in dataset:\n",
    "        fp.write(json.dumps(item) + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out langchain has a function for splitting text using `tiktoken` already... See [here](https://langchain.readthedocs.io/en/latest/modules/utils/combine_docs_examples/textsplitter.html#tiktoken-openai-length-function).\n",
    "\n",
    "It is built into the `CharacterTextSplitter`, and with a single function we can separate using the `\".\\n\"` we used before, we include the `encoder_name` as before, the `max_tokens`, and we can even set a `chunk_overlap` with a single parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator='\\n',\n",
    "    encoding_name=encoder_name,\n",
    "    chunk_size=max_tokens,\n",
    "    chunk_overlap=100  # let's add a small 2-4 sentence overlap\n",
    ")\n",
    "paper_chunks = text_splitter.split_text(paper)\n",
    "len(paper_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['REPLUG: Retrieval-Augmented Black-Box Language Models\\nWeijia Shi,1 *Sewon Min,1Michihiro Yasunaga,2Minjoon Seo,3Rich James,4Mike Lewis,4\\nLuke Zettlemoyer1 4Wen-tau Yih4\\nAbstract\\nWe introduce REPLUG, a retrieval-augmented lan-\\nguage modeling framework that treats the lan-\\nguage model (LM) as a black box and augments\\nit with a tuneable retrieval model. Unlike prior\\nretrieval-augmented LMs that train language mod-\\nels with special cross attention mechanisms to en-\\ncode the retrieved text, REPLUG simply prepends\\nretrieved documents to the input for the frozen\\nblack-box LM. This simple design can be eas-\\nily applied to any existing retrieval and language\\nmodels. Furthermore, we show that the LM can\\nbe used to supervise the retrieval model, which\\ncan then ﬁnd documents that help the LM make\\nbetter predictions. Our experiments demonstrate\\nthatREPLUG with the tuned retriever signiﬁcantly\\nimproves the performance of GPT-3 (175B) on\\nlanguage modeling by 6.3%, as well as the perfor-\\nmance of Codex on ﬁve-shot MMLU by 5.1%.\\n1. Introduction\\nLarge language models (LLMs) such as GPT-3 (Brown et al.,\\n2020a) and Codex (Chen et al., 2021a), have demonstrated\\nimpressive performance on a wide range of language tasks.\\nThese models are typically trained on very large datasets and\\nstore a substantial amount of world or domain knowledge\\nimplicitly in their parameters. However, they are also prone\\nto hallucination and cannot represent the full long tail of\\nknowledge from the training corpus. Retrieval-augmented\\nlanguage models (Khandelwal et al., 2020; Borgeaud et al.,\\n2022; Izacard et al., 2022b; Yasunaga et al., 2022), in con-\\ntrast, can retrieve knowledge from an external datastore\\nwhen needed, potentially reducing hallucination and increas-\\ning coverage. Previous approaches of retrieval-augmented\\nlanguage models require access to the internal LM repre-\\nsentations (e.g., to train the model (Borgeaud et al., 2022;\\n1University of Washington2Stanford University3KAIST4Meta\\nAI.\\n*Work done while the ﬁrst author was interning at Meta AI.\\nCorrespondence to: Weijia Shi <swj0419@uw.edu>.\\nFigure 1. Different from previous retrieval-augmented ap-\\nproaches (Borgeaud et al., 2022) that enhance a language model\\nwith retrieval by updating the LM’s parameters, REPLUG treats\\nthe language model as a black box and augments it with a frozen\\nor tunable retriever. This black-box assumption makes REPLUG\\napplicable to large LMs (i.e., >100B parameters), which are often\\nserved via APIs.',\n",
       " 'Figure 1. Different from previous retrieval-augmented ap-\\nproaches (Borgeaud et al., 2022) that enhance a language model\\nwith retrieval by updating the LM’s parameters, REPLUG treats\\nthe language model as a black box and augments it with a frozen\\nor tunable retriever. This black-box assumption makes REPLUG\\napplicable to large LMs (i.e., >100B parameters), which are often\\nserved via APIs.\\nIzacard et al., 2022b) or to index the datastore (Khandelwal\\net al., 2020)), and are thus difﬁcult to be applied to very\\nlarge LMs. In addition, many best-in-class LLMs can only\\nbe accessed through APIs. Internal representations of such\\nmodels are not exposed and ﬁne-tuning is not supported.\\nIn this work, we introduce REPLUG (Retrieve and Plug ),\\na new retrieval-augmented LM framework where the lan-\\nguage model is viewed as a black box and the retrieval\\ncomponent is added as a tuneable plug-and-play module.\\nGiven an input context, REPLUG ﬁrst retrieves relevant\\ndocuments from an external corpus using an off-the-shelf\\nretrieval model. The retrieved documents are prepended to\\nthe input context and fed into the black-box LM to make\\nthe ﬁnal prediction. Because the LM context length limits\\nthe number of documents that can be prepended, we also\\nintroduce a new ensemble scheme that encodes the retrieved\\ndocuments in parallel with the same black-box LM, allow-\\ning us to easily trade compute for accuracy. As shown inarXiv:2301.12652v2  [cs.CL]  1 Feb 2023REPLUG: Retrieval-Augmented Black-Box Language Models\\nFigure 1, REPLUG is extremely ﬂexible and can be used\\nwith any existing black-box LM and retrieval model.\\nWe also introduce REPLUG LSR (REPLUG with LM-\\nSupervised Retrieval), a training scheme that can further\\nimprove the initial retrieval model in REPLUG with super-\\nvision signals from a black-box language model. The key\\nidea is to adapt the retriever to the LM, which is in contrast\\nto prior work (Borgeaud et al., 2022) that adapts language\\nmodels to the retriever. We use a training objective which\\nprefers retrieving documents that improve language model\\nperplexity, while treating the LM as a frozen, black-box\\nscoring function.\\nOur experiments show that REPLUG can improve the perfor-\\nmance of diverse black-box LMs on both language modeling\\nand downstream tasks, including MMLU (Hendrycks et al.,\\n2021) and open-domain QA (Kwiatkowski et al., 2019; Joshi\\net al., 2017). For instance, REPLUG can improve Codex\\n(175B) performance on MMLU by 4.5%, achieving compa-\\nrable results to the 540B, instruction-ﬁnetuned Flan-PaLM.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_chunks[:2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the roughly paragraph-sized overlap in the text `\"Figure 1. Different from previous retrieval-augmented ap-\\nproaches (Borgeaud et al., 2022) that enhance a language model\\nwith retrieval by updating the LM’s parameters, REPLUG treats\\nthe language model as a black box and augments it with a frozen\\nor tunable retriever. This black-box assumption makes REPLUG\\napplicable to large LMs (i.e., >100B parameters), which are often\\nserved via APIs.\"`.\n",
    "\n",
    "Let's integrate this into the previous code to create a new dataset using the `langchain` implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a7c8e561f14ef8a2bafe564f7e90c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1410, which is longer than the specified 650\n",
      "Created a chunk of size 1360, which is longer than the specified 650\n",
      "Created a chunk of size 1950, which is longer than the specified 650\n",
      "Created a chunk of size 907, which is longer than the specified 650\n",
      "Created a chunk of size 897, which is longer than the specified 650\n",
      "Created a chunk of size 903, which is longer than the specified 650\n",
      "Created a chunk of size 935, which is longer than the specified 650\n",
      "Created a chunk of size 2127, which is longer than the specified 650\n",
      "Created a chunk of size 2139, which is longer than the specified 650\n",
      "Created a chunk of size 716, which is longer than the specified 650\n"
     ]
    }
   ],
   "source": [
    "langchain_dataset = []\n",
    "\n",
    "for paper_path in tqdm(paper_paths):\n",
    "    doi = paper_path.split('/')[-1][:-4]\n",
    "    with open(paper_path) as f:\n",
    "        paper = f.read()\n",
    "    paper_chunks = text_splitter.split_text(paper)\n",
    "    for i, chunk in enumerate(paper_chunks):\n",
    "        langchain_dataset.append({\n",
    "            'doi': doi,\n",
    "            'chunk-id': i,\n",
    "            'chunk': chunk\n",
    "        })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason we're seeing these errors is because the `text_splitter` only splits on `\\n` characters — and it seems that there are instances where there are *no* `\\n` characters for more than `650` tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk too long: 678\n"
     ]
    }
   ],
   "source": [
    "for i, record in enumerate(langchain_dataset):\n",
    "    chunk = record['chunk']\n",
    "    if len(tokenizer.encode(chunk)) > max_tokens:\n",
    "        print(f'Chunk too long: {len(tokenizer.encode(chunk))}')\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concerningly, this `678` length chunk didn't seem to be raised in the log of longer than specified length chunks above. Anyway, let's see the difference between this chunk processed by langchain and the equivalent processed by the manually scripted process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doi': '2302.00509',\n",
       " 'chunk-id': 0,\n",
       " 'chunk': 'Exploring Semantic Perturbations on Grover\\nCMSC 473/673: Capstone in Machine Learning\\nZiqing Ji, Pranav Kulkarni, Marko Neskovic, Kevin Nolan, Yan Xu\\n21 December 2021\\nhttps://github.com/itspranavk/cmsc473fall21-grover\\nAbstract\\nWith news and information being as easy to access as they currently are, it is more important than ever to\\nensure that people are not mislead by what they read. Recently, the rise of neural fake news (AI-generated fake\\nnews) and its demonstrated e\\x0bectiveness at fooling humans has prompted the development of models to detect\\nit. One such model is the Grover model, which can both detect neural fake news to prevent it, and generate it to\\ndemonstrate how a model could be misused to fool human readers. In this work we explore the Grover model\\'s\\nfake news detection capabilities by performing targeted attacks through perturbations on input news articles.\\nThrough this we test Grover\\'s resilience to these adversarial attacks and expose some potential vulnerabilities\\nwhich should be addressed in further iterations to ensure it can detect all types of fake news accurately.\\n1 Introduction and Literature\\n1.1 The Rise of Machine-Generated Fake News\\nWhile the term \\\\fake news\" has become politically charged in recent years, researchers of online misinformation\\ntypically de\\x0cne it as a form of propaganda that knowingly transmits false information to readers, viewers, or users\\n[2]. This de\\x0cnition is rather broad, with many academics o\\x0bering their own take. Alcott and Gentzkow describe\\nfake news as \\\\news articles that are intentionally and veri\\x0cably false, and could mislead readers\" [1]. Wardle and\\nDerakhshan posit seven categories of fake news, which together make a scale ranging from simple satire to fully\\nfabricated content [13]. For the purposes of this project, we will de\\x0cne fake news as any text that is created with the\\nintention of imparting false information onto the reader to achieve the goal of the disseminator. This includes, as\\nZellers et Al. describe, \\\\targeted propaganda that closely mimics the style of real news\" [16]. Taken this way, fake\\nnews has been present in social and political discourse for thousands of years. In one of the earliest cited examples\\nof fake news, Ramses the Great of Ancient Egypt spread propaganda portraying the Battle of Kadesh as a glowing\\nvictory for Egypt over the Hittites. The Treaty of Kadesh reveals that in fact, the battle ended in stalemate [14].\\nIn the modern era, fake news can pose great threats in democracy, politics, economy, and so on [5, 1, 12]. Creating\\nand consuming high quality misinformation is notably easier over the internet compared to print media [11, 1]. The\\ncurrent deep learning methods in natural language processing [4, 9] can automatically generate texts, and they can\\nbe applied to fake news generation, making it harder to tell whether a given article is authentic or fake. This change\\nin ease has caused a dramatic increase in the proliferation of fabricated content using social media [8].'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain_dataset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doi': '2302.00509',\n",
       " 'chunk-id': 0,\n",
       " 'chunk': 'Exploring Semantic Perturbations on Grover\\nCMSC 473/673: Capstone in Machine Learning\\nZiqing Ji, Pranav Kulkarni, Marko Neskovic, Kevin Nolan, Yan Xu\\n21 December 2021\\nhttps://github.com/itspranavk/cmsc473fall21-grover\\nAbstract\\nWith news and information being as easy to access as they currently are, it is more important than ever to\\nensure that people are not mislead by what they read. Recently, the rise of neural fake news (AI-generated fake\\nnews) and its demonstrated e\\x0bectiveness at fooling humans has prompted the development of models to detect\\nit. One such model is the Grover model, which can both detect neural fake news to prevent it, and generate it to\\ndemonstrate how a model could be misused to fool human readers. In this work we explore the Grover model\\'s\\nfake news detection capabilities by performing targeted attacks through perturbations on input news articles.\\nThrough this we test Grover\\'s resilience to these adversarial attacks and expose some potential vulnerabilities\\nwhich should be addressed in further iterations to ensure it can detect all types of fake news accurately.\\n1 Introduction and Literature\\n1.1 The Rise of Machine-Generated Fake News\\nWhile the term \\\\fake news\" has become politically charged in recent years, researchers of online misinformation\\ntypically de\\x0cne it as a form of propaganda that knowingly transmits false information to readers, viewers, or users\\n[2]. This de\\x0cnition is rather broad, with many academics o\\x0bering their own take. Alcott and Gentzkow describe\\nfake news as \\\\news articles that are intentionally and veri\\x0cably false, and could mislead readers\" [1]. Wardle and\\nDerakhshan posit seven categories of fake news, which together make a scale ranging from simple satire to fully\\nfabricated content [13]. For the purposes of this project, we will de\\x0cne fake news as any text that is created with the\\nintention of imparting false information onto the reader to achieve the goal of the disseminator. This includes, as\\nZellers et Al. describe, \\\\targeted propaganda that closely mimics the style of real news\" [16]. Taken this way, fake\\nnews has been present in social and political discourse for thousands of years. In one of the earliest cited examples\\nof fake news, Ramses the Great of Ancient Egypt spread propaganda portraying the Battle of Kadesh as a glowing\\nvictory for Egypt over the Hittites. The Treaty of Kadesh reveals that in fact, the battle ended in stalemate [14].\\nIn the modern era, fake news can pose great threats in democracy, politics, economy, and so on [5, 1, 12]. Creating\\nand consuming high quality misinformation is notably easier over the internet compared to print media [11, 1]. The\\ncurrent deep learning methods in natural language processing [4, 9] can automatically generate texts, and they can'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[i]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the `langchain` implementation didn't split the text where the manually written implementation did. As for why, I don't know. But because of this I will avoid using it and stick with the first version."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8e7999f96e1b425e2d542f21b571f5a4be3e97158b0b46ea1b2500df63956ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
